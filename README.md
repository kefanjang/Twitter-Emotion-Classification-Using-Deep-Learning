Utilized PyTorch for model development ; built and compared five models (MLP, CNN, LSTM, GRU, MLP-TF-IDF) for emotion classification, achieving an F1-score of 0.91 with LSTM on 250k tweets.
Designed a preprocessing pipeline (tokenization, lemmatization, stopword removal) to improve text data quality and model performance.
Analyzed model efficiency across varying dataset sizes, providing insights into balancing complexity and scalability.
